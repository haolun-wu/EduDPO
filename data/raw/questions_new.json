[
    {
        "id": 0,
        "question_text": "Program A will run 20 algorithms in sequence, with the running time for each algorithm being independent random variables with mean = 50 seconds and variance = 100 seconds$^2$. Program B will run 20 algorithms in sequence, with the running time for each algorithm being independent random variables with mean = 52 seconds and variance = 200 seconds$^2$. What is the approximate probability that Program A completes in less time than B? Give an answer to three decimal places.",
        "ta_solution": "Let $X_A$ be the running time of program A, and $X_B$ be the running time of program B. Using the Central Limit Theorem, we can find the distributions of $X_A$ and $X_B$:\n\n\\[\nX_A \\sim \\mathcal{N}(\\mu = 20 \\cdot 50,\\ \\sigma^2 = 20 \\cdot 100)\n\\]\n\\[\nX_B \\sim \\mathcal{N}(\\mu = 20 \\cdot 52,\\ \\sigma^2 = 20 \\cdot 200)\n\\]\n\nDefine a new random variable $X_{A-B}$, representing the difference in running times between program A and program B. Since the sum or difference between two normal random variables is also normal:\n\n\\[\nX_{A-B} \\sim \\mathcal{N}(\\mu = 1000 - 1040,\\ \\sigma^2 = 2000 + 4000)\n\\]\n\\[\nX_{A-B} \\sim \\mathcal{N}(-40,\\ 6000)\n\\]\n\nNote that we subtract the means, but add the variances. This is because subtracting the two normals is the same as transforming $X_B$ into $(-1) \\cdot X_B$, then adding that to $X_A$.\n\nIf program A finishes in less time than program B, then $X_{A-B} < 0$. We can calculate the probability of this as:\n\n\\[\nP(X_{A-B} < 0) = \\Phi\\left( \\frac{0 - (-40)}{\\sqrt{6000}} \\right)\n= \\Phi(0.516) \\approx 0.697\n\\]"
    }
]